{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "import igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/poulami/Documents/Github/Peer-Review-Analysis/data/personreview.csv')  #Enter path of the file personreview.csv\n",
    "#person = pd.read_csv('/home/poulami/Documents/Github/Peer-Review-Analysis/data/person.csv')\n",
    "review = pd.read_csv('/home/poulami/Documents/Github/Peer-Review-Analysis/data/result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate network\n",
    "### vertices  -  persons\n",
    "### edges - no of common reviews commented on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generatenetwork (start, end, index):\n",
    "    \n",
    "    \n",
    "    df1 = df\n",
    "    df1['date'] = df['date'].apply(pd.to_datetime, errors='coerce')      #typecasts the column date to type datetime\n",
    "    #print(df1.dtypes)\n",
    "    df1=df1.sort_values(by='date')                                        #Sorts the dataframe in ascending order of dates\n",
    "    #print(df1)\n",
    "    #start = input(\"Enter start date (yyyymmdd):\")\n",
    "    #end = input(\"Enter end date (yyyymmdd):\")\n",
    "    s = datetime.datetime.strptime(str(start), '%Y-%m-%d %H:%M:%S.%f')\n",
    "    e = datetime.datetime.strptime(str(end) , '%Y-%m-%d %H:%M:%S.%f')\n",
    "    df1 = df1.set_index(['date'])                                         #Required for the next step.  Sets date as an index\n",
    "    df1 = df1.loc[s:e]                                                    #Takes only the comments made between dates s and e\n",
    "    df1 = df1.reset_index(drop=True)                                      #Drops the index column 'date' as it is not needed anymore  \n",
    "    df1 = df1.drop_duplicates(subset=['sender', 'issue'])                 #Removes duplicate columns\n",
    "    print('top')\n",
    "    print(df1.shape[0])\n",
    "    \n",
    "    ##################################################################################\n",
    "    #    Compares the data frames w.r.t the set keys and extracts selected rows      #\n",
    "    ##################################################################################\n",
    "\n",
    "    person = df1.drop_duplicates(['sender'])\n",
    "    review = df1.drop_duplicates(['issue'])\n",
    "    keys = ['sender']\n",
    "    i1 = df1.set_index(keys).index\n",
    "    i2 = person.set_index(keys).index\n",
    "    df1 = df1[i1.isin(i2)]\n",
    "    keys = ['issue']\n",
    "    i1 = df1.set_index(keys).index\n",
    "    i2 = review.set_index(keys).index\n",
    "    df1 = df1[i1.isin(i2)]\n",
    "    #print(df1)\n",
    "    ##################################################################################\n",
    "    #                          Initialize the graph                                  #\n",
    "    ##################################################################################\n",
    "    g = Graph.Full(0)\n",
    "    print(person.shape[0])\n",
    "    for i in (person['sender']):\n",
    "        g.add_vertices([i])\n",
    "        #print(g)\n",
    "    g.es[\"weight\"]=0\n",
    "    ##################################################################################\n",
    "    #                    Creating edges and assigning edge weights                   #\n",
    "    ##################################################################################\n",
    "    df1 = df1[df1.duplicated(subset=['issue'] ,keep=False)]               #Keeps only the the reviews which occur twice. This is done because \n",
    "    #print('edgecre')                                                            \n",
    "    sender = df1[['sender']]                                                                                                                                               #\n",
    "    #print(sender)              2008-09-02 20:13:34.526552 2008-10-03 05:28:56.748409                                                                                                                                            #  CAN BE IMPROVED\n",
    "    sender = sender.drop_duplicates(subset=['sender'],keep= 'first' )     #Gets unique sender names along with issues (The  dataframe sender is used for looping through)  #\n",
    "    print('1')                         \n",
    "    for i in (sender['sender']):   \n",
    "        set1=df1[df1['sender'].isin([i])]                                 #Create first set                                                           \n",
    "        sender = sender.drop(sender.index[0])                             #Deletes the first element of sender   \n",
    "        for j in (sender['sender']):                                      #Creates second set               \n",
    "            set2=df1[df1['sender'].isin([j])]\n",
    "            newset = pd.concat([set1, set2])                              #set union\n",
    "            #print(newset)\n",
    "            newset = newset[newset.duplicated(subset=['issue'] ,keep='first')]  #Set intersection\n",
    "            weight = (newset.shape[0])\n",
    "            if(weight != 0):\n",
    "                g[i,j] = weight\n",
    "    g.vs['id'] = g.vs['name']                                             #assigns vertex id\n",
    "    g.write_pajek((\"T\" + str(index+1) + \"-nw.net\"))                                             #writes to pajek file\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generatenetwork('2008-09-02 20:13:34.526552', '2008-10-03 05:28:56.748409',1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate network graph for each time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-09-02 20:13:34.526552 \n",
      " 2012-10-31 03:02:05.619400\n",
      "30 days, 9:15:22.221857\n",
      "0 2008-09-02 20:13:34.526552 2008-09-02 20:13:34.526552 2008-10-03 05:28:56.748409\n",
      "1 2008-10-03 05:28:56.748409 2008-09-02 20:13:34.526552 2008-11-02 14:44:18.970266\n",
      "2 2008-11-02 14:44:18.970266 2008-09-02 20:13:34.526552 2008-12-02 23:59:41.192123\n",
      "3 2008-12-02 23:59:41.192123 2008-09-02 20:13:34.526552 2009-01-02 09:15:03.413980\n",
      "4 2009-01-02 09:15:03.413980 2008-09-02 20:13:34.526552 2009-02-01 18:30:25.635837\n",
      "5 2009-02-01 18:30:25.635837 2008-09-02 20:13:34.526552 2009-03-04 03:45:47.857694\n",
      "6 2009-03-04 03:45:47.857694 2008-09-02 20:13:34.526552 2009-04-03 13:01:10.079551\n",
      "7 2009-04-03 13:01:10.079551 2008-09-02 20:13:34.526552 2009-05-03 22:16:32.301408\n",
      "8 2009-05-03 22:16:32.301408 2008-09-02 20:13:34.526552 2009-06-03 07:31:54.523265\n",
      "9 2009-06-03 07:31:54.523265 2008-09-02 20:13:34.526552 2009-07-03 16:47:16.745122\n",
      "10 2009-07-03 16:47:16.745122 2008-09-02 20:13:34.526552 2009-08-03 02:02:38.966979\n",
      "11 2009-08-03 02:02:38.966979 2008-09-02 20:13:34.526552 2009-09-02 11:18:01.188836\n",
      "12 2009-09-02 11:18:01.188836 2008-09-02 20:13:34.526552 2009-10-02 20:33:23.410693\n",
      "13 2009-10-02 20:33:23.410693 2008-09-02 20:13:34.526552 2009-11-02 05:48:45.632550\n",
      "14 2009-11-02 05:48:45.632550 2008-09-02 20:13:34.526552 2009-12-02 15:04:07.854407\n",
      "15 2009-12-02 15:04:07.854407 2008-09-02 20:13:34.526552 2010-01-02 00:19:30.076264\n",
      "16 2010-01-02 00:19:30.076264 2008-09-02 20:13:34.526552 2010-02-01 09:34:52.298121\n",
      "17 2010-02-01 09:34:52.298121 2008-09-02 20:13:34.526552 2010-03-03 18:50:14.519978\n",
      "18 2010-03-03 18:50:14.519978 2008-09-02 20:13:34.526552 2010-04-03 04:05:36.741835\n",
      "19 2010-04-03 04:05:36.741835 2008-09-02 20:13:34.526552 2010-05-03 13:20:58.963692\n",
      "20 2010-05-03 13:20:58.963692 2008-09-02 20:13:34.526552 2010-06-02 22:36:21.185549\n",
      "21 2010-06-02 22:36:21.185549 2008-09-02 20:13:34.526552 2010-07-03 07:51:43.407406\n",
      "22 2010-07-03 07:51:43.407406 2008-09-02 20:13:34.526552 2010-08-02 17:07:05.629263\n",
      "23 2010-08-02 17:07:05.629263 2008-09-02 20:13:34.526552 2010-09-02 02:22:27.851120\n",
      "24 2010-09-02 02:22:27.851120 2008-09-02 20:13:34.526552 2010-10-02 11:37:50.072977\n",
      "25 2010-10-02 11:37:50.072977 2008-09-02 20:13:34.526552 2010-11-01 20:53:12.294834\n",
      "26 2010-11-01 20:53:12.294834 2008-09-02 20:13:34.526552 2010-12-02 06:08:34.516691\n",
      "27 2010-12-02 06:08:34.516691 2008-09-02 20:13:34.526552 2011-01-01 15:23:56.738548\n",
      "28 2011-01-01 15:23:56.738548 2008-09-02 20:13:34.526552 2011-02-01 00:39:18.960405\n",
      "29 2011-02-01 00:39:18.960405 2008-09-02 20:13:34.526552 2011-03-03 09:54:41.182262\n",
      "30 2011-03-03 09:54:41.182262 2008-09-02 20:13:34.526552 2011-04-02 19:10:03.404119\n",
      "31 2011-04-02 19:10:03.404119 2008-09-02 20:13:34.526552 2011-05-03 04:25:25.625976\n",
      "32 2011-05-03 04:25:25.625976 2008-09-02 20:13:34.526552 2011-06-02 13:40:47.847833\n",
      "33 2011-06-02 13:40:47.847833 2008-09-02 20:13:34.526552 2011-07-02 22:56:10.069690\n",
      "34 2011-07-02 22:56:10.069690 2008-09-02 20:13:34.526552 2011-08-02 08:11:32.291547\n",
      "35 2011-08-02 08:11:32.291547 2008-09-02 20:13:34.526552 2011-09-01 17:26:54.513404\n",
      "36 2011-09-01 17:26:54.513404 2008-09-02 20:13:34.526552 2011-10-02 02:42:16.735261\n",
      "37 2011-10-02 02:42:16.735261 2008-09-02 20:13:34.526552 2011-11-01 11:57:38.957118\n",
      "38 2011-11-01 11:57:38.957118 2008-09-02 20:13:34.526552 2011-12-01 21:13:01.178975\n",
      "39 2011-12-01 21:13:01.178975 2008-09-02 20:13:34.526552 2012-01-01 06:28:23.400832\n",
      "40 2012-01-01 06:28:23.400832 2008-09-02 20:13:34.526552 2012-01-31 15:43:45.622689\n",
      "41 2012-01-31 15:43:45.622689 2008-09-02 20:13:34.526552 2012-03-02 00:59:07.844546\n",
      "42 2012-03-02 00:59:07.844546 2008-09-02 20:13:34.526552 2012-04-01 10:14:30.066403\n",
      "43 2012-04-01 10:14:30.066403 2008-09-02 20:13:34.526552 2012-05-01 19:29:52.288260\n",
      "44 2012-05-01 19:29:52.288260 2008-09-02 20:13:34.526552 2012-06-01 04:45:14.510117\n",
      "45 2012-06-01 04:45:14.510117 2008-09-02 20:13:34.526552 2012-07-01 14:00:36.731974\n",
      "46 2012-07-01 14:00:36.731974 2008-09-02 20:13:34.526552 2012-07-31 23:15:58.953831\n",
      "47 2012-07-31 23:15:58.953831 2008-09-02 20:13:34.526552 2012-08-31 08:31:21.175688\n",
      "48 2012-08-31 08:31:21.175688 2008-09-02 20:13:34.526552 2012-09-30 17:46:43.397545\n",
      "49 2012-09-30 17:46:43.397545 2008-09-02 20:13:34.526552 2012-10-31 03:02:05.619402\n"
     ]
    }
   ],
   "source": [
    "head = datetime.datetime.strptime('2008-09-02 20:13:34.526552', '%Y-%m-%d %H:%M:%S.%f') \n",
    "tail = datetime.datetime.strptime('2012-10-31 03:02:05.619400', '%Y-%m-%d %H:%M:%S.%f') \n",
    "print(head,'\\n',tail)\n",
    "step = (tail-head)/50\n",
    "print(step)\n",
    "sum=0\n",
    "for i in range(0,50):\n",
    "        start  = head+i*step\n",
    "        end = head +(1+i)*step\n",
    "        print(i,start, head, end)\n",
    "        generatenetwork(head, end,i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
